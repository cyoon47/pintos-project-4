       	     	     +-------------------------+
		     |	 2017  fall  CS 330    |
		     | PROJECT 4: FILE SYSTEMS |
		     |	   DESIGN DOCUMENT     |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.
>> You can write this document in Korean! (We recommend!)

Mingi Shin <yuagnun@gmail.com>
Chang Yoon Lee <cyoon47@kaist.ac.kr>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

Team 1, project 4, 5 tokens

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

From filesys/inode.c

struct inode_disk
  {
    off_t length;                       
    unsigned magic;                     
    disk_sector_t start_block;
    unsigned allocated;
    unsigned inner_index;
    unsigned outer_index;
    unsigned isdir;
    disk_sector_t parent_sector;
    uint32_t unused[120];               
  };
disk_sector_t start_block: the sector number for the initial block in the doubly indirect inode.

unsigned allocated: variable to indicate whether the initial block is allocated. We used unsigned as it is 4 bytes long, and it is easier to keep 512 bytes constraint.

unsigned inner_index: the current index to the first layer of indirect blocks.

unsigned outer_index: the next index to the second layer of indirect blocks.

struct indirect_block
{
  disk_sector_t disk_ptr[DISK_NUM_PTR];
};

struct indirect_block contains 128 disk_sector_t for each indirect access to another block.
disk_ptr contains the sector numbers for each block.

struct inode 
  {
    struct list_elem elem;              
    disk_sector_t sector;               
    int open_cnt;                       
    bool removed;                       
    int deny_write_cnt;                 
    off_t length;
    disk_sector_t start_block;
    unsigned allocated;
    unsigned inner_index;
    unsigned outer_index;
    unsigned isdir;
    disk_sector_t parent_sector;
    struct lock lock;
    off_t visible_length;
  };

disk_sector_t start_block, unsigned allocated, unsigned inner_index, and unsigned outer_index all have the same meaning as variables of the same names in struct inode_disk.
off_t visible_length represents the length of the file that a reader can access, for controlling race condition during file extension.


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

Our inode structure has one doubly indirect block. Since the disk sector size is 512 bytes, and each disk_sector_t is 4 bytes, one indirect block can store 512/4 = 128 disk_sector_t to another block. Therefore, the maximum size of a file is 128*128*512 = 8338608 bytes = 8 MB. Since we need to implement a file up to size of 8MB - metadata, one doubly indirect block should suffice.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

In our code, in inode_write_at(), a process needs to acquire the lock to the file’s inode before it attempts to extend the file. Since the lock is released only when the process finishes extending the file, any other process cannot try to extend the file before one finishes. This solves the race condition when two or more processes attempt to extend a file, by ensuring exclusion in extending a file.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

This is solved using two ‘lengths’ in the inode, which are off_t length, and off_t visible_length. visible_length represents the length of the file that is ‘visible’ to a reading process, which is incremented by chunk_size only when data of size chunk_size is actually written to the file. This way, only the data written by B is visible to A, and A cannot see any zeros that B did not write, preventing any race condition while extending the file.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

In our synchronization design, no lock that allows readers to block writers nor a lock that allows writers to block readers is used. There is no way for writers and readers to prevent each other from accessing the file they are using.
Since there is no way of interacting with other processes using the file, the file data might be interleaved, or only a part of written data might be seen by the reader. However, this is allowed as mentioned in the pintos document, therefore there is no problem caused by making all accesses to files independent.
The only interaction between reader and writer occurs when reader tries to read past EOF while writer is extending the file, but even in this case, the writer allows reader to read any written data as soon as they are available for the reader, minimizing the ‘blocking’ time.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

Yes. We used a single doubly indirect indexing. The requirement on the size of a file was 8MB, which is completely covered by a single doubly indirect block, so there was no need to use any direct blocks or indirect blocks. We did not use any other types of blocks since it meant introducing more complex inode structure, which will be more difficult to debug and manage. Using only one type of indirect block very much simplified the design and increased understandability of our code.

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

From filesys/inode.c

struct inode_disk
  {
    off_t length;                       
    unsigned magic;                     
    disk_sector_t start_block;
    unsigned allocated;
    unsigned inner_index;
    unsigned outer_index;
    unsigned isdir;
    disk_sector_t parent_sector;
    uint32_t unused[120];               
  };

unsigned isdir: a variable that indicates whether the inode represents a directory.

disk_sector_t parent_sector: the sector number containing the inode’s parent directory.

struct inode 
  {
    struct list_elem elem;              
    disk_sector_t sector;               
    int open_cnt;                       
    bool removed;                       
    int deny_write_cnt;                 
    off_t length;
    disk_sector_t start_block;
    unsigned allocated;
    unsigned inner_index;
    unsigned outer_index;
    unsigned isdir;
    disk_sector_t parent_sector;
    struct lock lock;
    off_t visible_length;
  };

unsigned isdir and disk_sector_t parent_sector have the same meaning as the variables in struct inode_disk.

From threads/thread.h:

struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          
    ...

    struct dir *curr_dir;

    ...
    unsigned magic;                     
  };

struct dir *curr_dir: the current directory that the process is in.

struct file_map
{
  int fd;
  struct file *file;
  struct dir *dir;
  bool isdir;
  struct list_elem elem;
};

struct dir *dir: the pointer to the corresponding struct dir when the open file represents a directory.

bool isdir: a variable to indicate whether the file_map represents a directory.



---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

The user-specified path is tokenized using ‘/’ that separates the path. The traversals of absolute and relative paths differ only at the start. When the path starts with ‘/’, then it must be an absolute path, so we set the starting directory as root. Otherwise, the path must be relative, and we set the starting directory as the process’s current directory.

After that, we go through each token to traverse the path. If ‘.’ is found, it represents the current directory so nothing is done. If ‘..’ is found, we change the directory to be the parent directory of the current directory. For all other cases, we look up the current directory for the name specified by the token. If the name does not exist in the current directory, then the path is invalid. This step is repeated until we get to the end of the given path.

>> B3: Look over "pwd.c" in src/examples.  Briefly explain how it
>> determines the present working directory.

First, it opens the current directory it is in and stores the inumber of the current directory using get_inumber() to child_inum. Then, set char *namep to the beginning of char name[].

Then, in an infinite loop, we append “..” at location of *namep. For the first loop, name[] will be “..”. Then, we use open system call to open path in name, which will be the parent directory of the current directory, and append ‘/’ at *namep, and now name[] is “../”. The result of open system call is stored in parent_fd. The inumber of opened parent_fd is stored in parent_inum.

In another infinite loop, we call readdir(parent_fd, namep), which will store the name of entries at *namep, and name[] will be “../[name_of_entry]”. We call get_inumber(name, &test_inum), which will get the inumber of the path stored in name. We go through the loop until test_inum == child_inum, which means that name[] is now “../[name_of_current_directory]”. Then, we prepend the name of current directory to cwd. Finally, child_inum is set to parent_inum, traversing upwards in the directory tree.

In the outer loop, name will be set to “../../.. …”, traversing up the directory tree, and getting the parent_inum. In the inner loop, the name of the child_inum will be found, and then exit the loop. Finally the name of the child directory will be prepended to cwd.

This continues until parent_inum == child_inum, which means that the parent directory is equal to child directory, which should only happen when we reached the root. When this happens, cwd should contain the full name of present working directory. The string in cwd is moved forward, and ‘/’ is added to the front of the string to give the complete absolute path of the present directory.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

This is prevented by using the inode_lock for the directory. In dir_lookup, dir_add, dir_remove and dir_readdir, which are all the cases when the system needs to look at the directory’s entries or change them, before any of the work is done, the process needs to acquire the lock to the directory’s inode. This means that only one process can access the directory’s entry information, and only one of the same attempts to remove or create a file should succeed, whichever does it first.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

No. Our implementation disallows removing of an open directory or a directory that is being used by a process. We made use of the inode’s open_cnt to check if any process is using the directory. If the directory’s inode’s open_cnt is greater than 1, it is not allowed to be removed. If open_cnt is greater than 1, it means that the directory is being used by some other process than the removing process. The directory’s inode will always be opened by once during the removal process, thus the limit is set to 1. 	

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

We placed struct dir * in struct thread. It was the most natural choice of representing the current directory, as current directory is specific within a single process. Also, using struct dir allowed us to perform all of the manipulations on the current directory of the process very easily using the functions implemented in filesys/directory.c.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

From filesys/cache.h

struct list cache_list: a list of cache blocks, representing the whole cache.
struct lock cache_lock: a lock that controls access to the cache.

enum access_mode
{
	FILE_READ,
	FILE_WRITE
};

The enum access_mode specifies the type of cache access, whether it is read or write.

struct cache_block
{
	uint8_t block[DISK_SECTOR_SIZE];	
	disk_sector_t disk_sector;			
	bool accessed;							
bool dirty;							
	unsigned num_access;				
	struct list_elem elem;
};

Uint8_t block[]: contains the data within the disk block.
disk_sector_t disk_sector: the disk sector number that the cache is loaded from.
bool accessed: indicates whether the cache block was accessed since it was loaded.
bool dirty: indicates whether the contents in the cache have been modified.
unsigned num_access: contains the number of processes accessing the cache. To be considered for eviction.
Struct list_elem elem: used to insert the cache in the cache_list.

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We used second chance algorithm. First, if the cache is being accessed by any process, it is not considered a candidate for eviction. Then, among the cache blocks that are not being accessed, check if it has been accessed before. If it was accessed before, the accessed variable is set to false. If it was not accessed before, we select that block to evict. If it has been modified before, then the contents are written to the disk before the cache is evicted. Finally, the new block is read from the disk to the cache.

>> C3: Describe your implementation of write-behind.

When the cache is initialized, a write-back thread is created. The function of the thread is to go through the cache list and check if each cache block is dirty. If it is dirty, then the contents of the cache block is written to the disk location specified by cache block’s disk_sector. After it is written, the dirty bit is set to false. After going through the whole list, the thread sleeps for WRITE_BACK_PERIOD, which is set to 3 seconds in our implementation. Thus, the write-back process is repeated every 3 seconds. 

>> C4: Describe your implementation of read-ahead.

Since read-ahead needs to be asynchronous, we created a thread to read the next sector of the disk. The thread will be created every time an access to disk occurs, fetching the next disk sector into the cache if it is not already in the cache.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

Similarly to our implementation of pages and swap slots, which did not allow eviction of a page being accessed using a boolean allow_swap, the buffer cache blocks have a variable num_access that is incremented every time a process reads or writes to the buffer. It is initialized to zero, and as processes access the block, it increases to a non-zero value. num_access is decremented when the read or write finishes. This way, num_access will be greater than 1 if there is a process accessing it. By skipping block with num_access > 0, we will not evict a block being used.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

During eviction, the process acquires cache_lock. Also, for every access to the cache, process needs to acquire the cache_lock. If a process is evicting the cache block, it must have acquired the cache_lock. No other process can access the cache since the lock is being held by another process. Lock is only released when eviction is complete, and if other processes want to get the block again, they need to bring it into the cache from the disk. 

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

A file workload that benefits from buffer caching is one that repeatedly accesses a few number of blocks. Since buffer caching brings those blocks into memory, access time will reduce greatly when compared to accessing the blocks from the disk itself.

Workload that benefits from read-ahead is a sequential read, such as watching video file. The system will asynchronously bring in subsequent blocks when a single block is read, and the process does not have to wait for the fetching of data from the disk, since the next block is already loaded in the cache.

A workload that benefits from write-behind is one that keeps writing to a small number of blocks. The writes will be done in memory, not directly to the disks, and thus saves a lot of time that would have been used to access the disks. With write-behind, those writes can be done to the memory, and written to disk only once in a while, potentially saving a lot of time.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?




